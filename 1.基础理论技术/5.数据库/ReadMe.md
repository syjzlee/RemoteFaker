<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [数据库篇](#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87)
  - [数据库系统概念](#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5)
    - [数据库范式](#%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F)
    - [视图](#%E8%A7%86%E5%9B%BE)
    - [游标](#%E6%B8%B8%E6%A0%87)
    - [触发器](#%E8%A7%A6%E5%8F%91%E5%99%A8)
    - [存储过程](#%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B)
  - [MySQL 基础问题](#mysql-%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98)
    - [常用 SQL 语句](#%E5%B8%B8%E7%94%A8-sql-%E8%AF%AD%E5%8F%A5)
    - [in与not in,exists与not exists的区别](#in%E4%B8%8Enot-inexists%E4%B8%8Enot-exists%E7%9A%84%E5%8C%BA%E5%88%AB)
    - [drop、delete 与 truncate 的区别](#dropdelete-%E4%B8%8E-truncate-%E7%9A%84%E5%8C%BA%E5%88%AB)
  - [数据库事务](#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1)
    - [事务的特征(ACID)](#%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%89%B9%E5%BE%81acid)
    - [事务并发带来的问题](#%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98)
    - [事务的隔离级别](#%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB)
    - [MySQL 的事务支持](#mysql-%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%94%AF%E6%8C%81)
  - [数据库索引](#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95)
    - [索引的优点和缺点](#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9)
    - [B 树和 B+ 树](#b-%E6%A0%91%E5%92%8C-b-%E6%A0%91)
    - [索引的分类](#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%B1%BB)
  - [MySQL 中的锁](#mysql-%E4%B8%AD%E7%9A%84%E9%94%81)
    - [乐观锁和悲观锁](#%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81)
    - [MySQL 行级锁](#mysql-%E8%A1%8C%E7%BA%A7%E9%94%81)
  - [存储引擎 MyISAM 和 InnoDB 区别](#%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E-myisam-%E5%92%8C-innodb-%E5%8C%BA%E5%88%AB)
  - [实现MVCC](#%E5%AE%9E%E7%8E%B0mvcc)
  - [实践中如何优化 MySQL](#%E5%AE%9E%E8%B7%B5%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-mysql)
    - [SQL 语句的优化](#sql-%E8%AF%AD%E5%8F%A5%E7%9A%84%E4%BC%98%E5%8C%96)
    - [索引的优化](#%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E5%8C%96)
    - [数据表结构的优化](#%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E4%BC%98%E5%8C%96)
  - [Redis](#redis)
    - [Redis数据类型](#redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B)
    - [Redis的应用场景](#redis%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF)
    - [Redis 持久化](#redis-%E6%8C%81%E4%B9%85%E5%8C%96)
    - [缓存使用过程中的坑](#%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%9D%91)
    - [其他问题](#%E5%85%B6%E4%BB%96%E9%97%AE%E9%A2%98)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 数据库篇
* 学习书籍推荐
    - [知乎龚子捷的回答](https://www.zhihu.com/question/34840297/answer/272185020)
    - [《高性能MySQL》](https://book.douban.com/subject/23008813/)
## 数据库系统概念
### [数据库范式](https://blog.csdn.net/ws13575291650/article/details/113743056)
**目的：减少数据冗余**   
一般的数据库只遵循第一范式，第二范式，第三范式就足够了。满足了这三个范式的数据库一般都是简单和结构清晰的，同时也不会发生insert，delete，update的操作异常。
* 第一范式：列不可分，eg:【联系人】（姓名，性别，电话），一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF；（**即数据库表的每一列都是不可分割的原子数据项**）
* 第二范式：一个表中只能保存一种实体，不能部分依赖。要有主键，保证完全依赖。eg:订单明细表【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName），Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID，不符合2NF；（**例如在员工表中的身份证号码即可实现每个一员工的区分，该身份证号码即为候选键，任何一个候选键都可以被选作主键。在找不到候选键时，可额外增加属性以实现区分，如果在员工关系中，没有对其身份证号进行存储，而姓名可能会在数据库运行的某个时间重复，无法区分出实体时，设计辟如ID等不重复的编号以实现区分，被添加的编号或ID选作主键。**）
* 第三范式：表里面的列不能出现其它表的非主键字段，不传递依赖(非主键列 A 依赖于非主键列B，非主键列 B 依赖于主键的情况)，eg: 订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），CustomerName，CustomerAddr，CustomerCity直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。（**第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个关系中不包含已在其它关系已包含的非主关键字信息。例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性，也就是在满足2NF的基础上，任何非主属性不得传递依赖于主属性。**）  
  
如何更好的区分三大范式：   

    * 第一范式在于有没有分出多列属性，即数据库表中的所有字段值都是不可分解的原子值
    * 第二范式是说一张表中包含了多种不同的实体属性，那么要必须分成多张表，即确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）  
    * 第三范式是要求已经分成了多张表，那么一张表中只能有另一张表中的id（主键），而不能有其他的任何信息（其他的信息一律用主键在另一表查询）。即确保数据表中的每一列都和主键直接相关，而不能间接相关。
优缺点:

    好处：冗余较小、结构合理
    坏处：适当的冗余可以提升查询的性能
    
 不遵循范式可能导致以下问题：
    
    信息重复
    更新异常
    插入异常
    删除异常
如果每张表都完全规范，性能反而会降低，考虑到商业化需求和目标，数据库的性能相对来说更要重，所以我们在规范设计的同时，也要考虑性能问题，那一般的选取是，关联查询的表不得超过三张，这也是阿里的数据库设计规范。

### 视图
* 视图是一种虚拟的表，通常是有一个表或者多个表的行或列的子集，具有和物理表相同的功能，可以对视图进行增，删，改，查等操作。特别地，对视图的修改不影响基本表。相比多表查询，它使得我们获取数据更容易。
### 游标
* 游标是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行，可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。 MySQL 检索操作返回一组称为结果集的行，这组返回的行都是与 SQL 语句相匹配的行（零行或多行），使用简单的 SELECT 语句，不存在每次一行地处理所有行的简单方法（相对于成批地处理它们）。有时需要在检索出来的行中前进或后退一行或多行，这就是使用游标的原因。游标（cursor）是一个存储在 MySQL 服务器上的数据库查询，它不是一条 SELECT 语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。  

优点： 
 
    1、允许程序对由查询语句select返回的行集合中的每一行执行相同或不同的操作，而不是对整个行集合执行同一个操作。    
    2、提供对基于游标位置的表中的行进行删除和更新的能力。
    3、游标实际上作为面向集合的数据库管理系统（RDBMS）和面向行的程序设计之间的桥梁，使这两种处理方式通过游标沟通起来。

原理：

    游标就是把数据按照指定要求提取出相应的数据集，然后逐条进行数据处理。

使用游标的顺序
 声名游标、打开游标、读取数据、关闭游标、删除游标。
### 触发器
[触发器 trigger](https://www.cnblogs.com/aaronthon/p/13299825.html)
* 触发器是与表相关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据库端确保数据库的完整性。
    
    
    create trigger trigger_name trigger_time trigger_event  on tb_name for each row trigger_statement;
        （1）trigger_name：要创建的触发器名称。
        （2）tb_name：建立触发器的表名，即在哪个表上建立触发器。tb_name 必须引用永久性表。
        （3）trigger_time：指定触发器触发的时机。以指明触发程序是在激活它的语句之前或之后触发。可以指定 before 或 after。
        （4）trigger_event：指明激活触发程序的语句的类型。trigger_event可以是下述值之一。
              ① insert：将新行插入表时触发程序。例如通过 insert、load data和replace语句。
              ② update：更改某一行时激活触发程序。例如通过update语句。
              ③ delete：从表中删除某一行时激活触发程序。例如通过delete和raplace语句。
        （5）for each row：触发器的执行间隔，通知触发器每隔一行执行一次动作，而不是对整个表执行一次。
        （6）trigger_statement：指定触发器所执行的 SQL 语句。可以使用 BEGIN...END 作为开始和结束
### 存储过程
* 存储过程是事先经过编译并存储在数据库中的一段 SQL语句的集合。存储过程是由一些 T-SQL 语句组成的代码块，这些 T-SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。存储过程具有以下特点：
    - 存储过程只在创建时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次，所以使用存储过程可提高数据库执行效率；
    - 当 SQL 语句有变动时，可以只修改数据库中的存储过程而不必修改代码；
    - 减少网络传输，在客户端调用一个存储过程当然比执行一串 SQL 传输的数据量要小；
    - 通过存储过程能够使没有权限的用户在控制之下间接地存取数据库，从而确保数据的安全。
## MySQL 基础问题
### 常用 SQL 语句
* [内连接，左连接，全连接](https://jingyan.baidu.com/article/9f7e7ec098f68b6f28155407.html)(https://blog.csdn.net/qq_34082034/article/details/54962531)   

        select a.name,b.job from A a  inner join B b on a.id=b.A_id   
        inner join：只返回两个表中连接字段相等的行。 
        left join：返回包括左表中的所有记录和右表中连接字段相等的记录。如果左表的某行在右表中没有匹配行，则相应的结果行中右表的所有选择列对应均为空值。
        right join：返回包括右表中的所有记录和左表中连接字段相等的记录。如果右表的某行在左表中没有匹配行，则相应的结果行中左表的所有选择列对应均为空值。
        full join(全外连接)：返回左右表中所有的记录和左右表中连接字段相等的记录。

* [union 和union all的区别](https://www.cnblogs.com/xiangshu/articles/2054447.html)：union会对结果集进行处理排除掉相同的结果，union all 不会对结果集进行处理，不会处理掉相同的结果。    

        Union因为要进行重复值扫描，所以效率低。如果合并没有刻意要删除重复行，那么就使用Union All
        两个要联合的SQL语句 字段个数必须一样，而且字段类型要“相容”（一致）；
        
        select employee_id,job_id from employees union select employee_id,job_id from job_history;
        Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；
        Union All：对两个结果集进行并集操作，包括重复行，不进行排序；
        Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序；
        Minus：对两个结果集进行差操作，不包括重复行，同时进行默认规则的排序。
* MySQL 常用数据类型：字符串、数值、日期
* 数据库查询语言分类
    - DQL（Data Query Language）数据查询语言DQL由SELECT子句，FROM子句，WHERE子句组成
    - DML（Data Manipulation Language）数据操纵语言DML包含INSERT，UPDATE，DELETE
    - DDL（Data Definition Language）数据定义语言DDL用来创建数据库中的各种对象-----表、视图、 索引、同义词、聚簇等，如：CREATE TABLE/VIEW/INDEX/SYN(同义词)/CLUSTER。DDL操作是隐性提交的！不能rollback
    - DCL（Data Control Language）数据控制语言（DCL）是用来设置或者更改数据库用户或角色权限的语句，这些语句包括GRANT、DENY、REVOKE(取消授权)等语句，在默认状态下，只有sysadmin、dbcreator、db_owner或db_securityadmin等角色的成员才有权利执行数据控制语言。
        - Grant：授权
        - Revoke： 取消授权
        - Rollback：回滚(回滚到数据库上次提交的状态：Rollback;)
            -  Rollback[work] to [savepoint]: 回退到某点
        - Commit：提交(插入修改删除操作后只有当事务提交才能算完成)
            - 显式提交：commit；
            - 隐式提交：SQL命令间接完成提交(如：alter, audit, noaudit, comment, connect, disconnect, create, drop, exit, quit, grant, revoke, rename)。
            - 设置自动提交：set autocommit on;
### [in与not in,exists与not exists的区别](https://www.cnblogs.com/SmallStrange/p/13869958.html)
* in与子查询一起使用的时候,只针对主查询使用索引，子查询不使用索引。（所以子查询表小的用in）
* exist会针对子查询的表使用索引。（所以子查询表大的用exists）
* not exist会对主子查询都会使用索引
* not in则不会使用任何索引（所以任何情况都应该使用not exists。比not in快和安全。 not in如果子查询存在某条记录为null时候则主查询不会返回任何记录）
* 如果查询的两个表大小相当，那么用in和exists差别不大；如果两个表中一个较小一个较大，则子查询表大的用exists，子查询表小的用in，所以无论哪个表大，用not exists都比not in 要快。
### drop、delete 与 truncate 的区别
* delete 用来删除表的全部或者一部分数据行，执行delete 之后，用户需要提交 (commmit) 或者回滚(rollback) 来执行删除或者撤销删除， delete 命令会触发这个表上所有delete 触发器；
* truncate 删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，truncate 比 delete 更快，占用的空间更小；
* drop 命令从数据库中删除表，所有的数据行，索引和权限也会被删除，所有的 DML 触发器也不会被触发，这个命令也不能回滚。
* 因此，在不再需要一张表的时候，用 drop；在想删除部分数据行时候，用 delete；在保留表而删除所有数据的时候用 truncate。
## [数据库事务](https://www.cnblogs.com/takumicx/p/9998844.html)
* 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。

        BEGIN TRANSACTION  //事务开始
        SQL1
        SQL2
        COMMIT/ROLLBACK   //事务提交或回滚
### 事务的特征(ACID)
* 原子性 (Atomicity)：事务所包含的一系列数据库操作要么全部成功执行，要么全部回滚；
* 一致性 (Consistency)：事务的执行结果必须使数据库从一个一致性状态到另一个一致性状态；
* 隔离性 (Isolation)：并发执行的事务之间不能相互影响；
* 持久性 (Durability)：事务一旦提交，对数据库中数据的改变是永久性的。
### 事务并发带来的问题
* 脏写：**脏写是指事务回滚了其他事务对数据项的已提交修改**,比如下面这种情况在事务1对数据A的回滚,导致事务2对A的已提交修改也被回滚了。   
* 丢失更新：**指事务覆盖了其他事务对数据的已提交修改,导致这些修改好像丢失了一样**。事务1和事务2读取A的值都为10,事务2先将A加上10并提交修改,之后事务2将A减少10并提交修改,A的值最后为0,导致事务2对A的修改好像丢失了一样    
* 脏读：**一个事务读取了另一个事务未提交的数据**；（eg：事务A：张三妻子给张三转账100元。事务B：张三查询余额。事务A转账后（还未提交），事务B查询多了100元。事务A由于某种问题，比如超时，进行回滚。事务B查询到的数据是假数据。）
* 不可重复读：**不可重复读的重点是修改，同样条件下两次读取结果不同**；（eg：事务A：张三妻子给张三转账100元。事务B：张三两次查询余额。事务B第一次查询余额，事务A还没有转账，第二次查询余额，事务A已经转账了，导致一个事务中，两次读取同一个数据，读取的数据不一致。）
* 幻读：**幻读的重点在于新增或者删除**，一个事务两次读取一个范围的记录，两次读取的记录数不一致。（eg：事务A：张三妻子两次查询张三有几张银行卡。事务B：张三新办一张银行卡。事务A第一次查询银行卡数的时候，张三还没有新办银行卡，第二次查询银行卡数的时候，张三已经新办了一张银行卡，导致两次读取的银行卡数不一样。）
### 事务的隔离级别
* 参考[数据库事务隔离级别-- 脏读、幻读、不可重复读（清晰解释）](https://blog.csdn.net/JIESA/article/details/51317164)
* 数据库事务的隔离级别有4个，由低到高依次为Read uncommitted(读未提交)、Read committed 、Repeatable read(可重复读)、Serializable(串行化)（最高级别的隔离，只允许事务串行执行。），后三个级别可以逐个解决脏读 、不可重复读 、幻读这几类问题，MySQL 的 InnoDB存储引擎都支持，MySQL 默认的隔离级别是 Repeatable read。
![Snipaste_2019-09-05_15-29-32.png](https://i.loli.net/2019/09/05/ajrmGC2HAhT1Lqf.png)
### MySQL 的事务支持
* MySQL 的事务支持不是绑定在 MySQL 服务器本身，而是与存储引擎相关：
    - MyISAM：不支持事务，用于只读程序提高性能；
    - InnoDB：支持 ACID 事务、行级锁、并发；
    - Berkeley DB：支持事务。
## 数据库索引
* 索引是对数据库表中一个或多个列的值进行排序的数据结构，以协助快速查询、更新数据库表中数据。**索引的实现通常使用 B树和B+树，索引加速了数据访问，因为存储引擎不会再去扫描整张表得到需要的数据；相反，它从根节点开始，根节点保存了子节点的指针，存储引擎会根据指针快速寻找数据。**
* 在数据结构中，我们最为常见的搜索结构就是二叉搜索树和 AVL 树 (高度平衡的二叉搜索树，为了提高二叉搜索树的效率，减少树的平均搜索长度) 了。然而，无论二叉搜索树还是 AVL 树，当数据量比较大时，都会由于树的深度过大而造成 I/O 读写过于频繁，进而导致查询效率低下，因此对于索引而言，B 树（平衡多路查找树）各操作能使 B 树保持较低的高度，从而保证高效的查找效率。
### 索引的优点和缺点
* 优点
    * 大大加快数据的检索速度，这也是创建索引的最主要的原因；
    * 加速表和表之间的连接；
    * 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间；
    * 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；
* 缺点
    * 时间方面：创建索引和维护索引要耗费时间，具体地对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；
    * 空间方面：索引需要占物理空间；
### [B 树和 B+ 树](https://blog.csdn.net/xt199711/article/details/112500937)
* [二叉树、平衡二叉树、二叉查找树](https://mp.weixin.qq.com/s/K_oGI2rl3epTirxkST5LVQ)
* 参考[重温数据结构：理解 B 树、B+ 树特点及使用场景](https://blog.csdn.net/u011240877/article/details/80490663)
* B树与B+树示意图
    - B树    
![B树](https://img-blog.csdnimg.cn/20200405155635665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNjk4NDIy,size_16,color_FFFFFF,t_70)
    - B+树    
![B+树](https://img-blog.csdnimg.cn/20200405161242361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNjk4NDIy,size_16,color_FFFFFF,t_70)
    - 关于平衡二叉树和红黑树以及B树和B+树自己的理解:
        - 平衡二叉树：是带有平衡条件的二叉查找树，左右子树树高不超过1，和红黑树比是严格的平衡二叉树，在插入和删除操作时都要通过旋转保持平衡，而旋转非常好使，所以平衡二叉树适合用于插入删除操作比较少但是查找多的情况。
        - 红黑树：是每个节点非红即黑，根节点和每个叶节点都是黑的，如果一个节点是红的那两个子节点也就都是黑色，每条路径都包含相同的黑节点。
        - B树:相对于平衡二叉树优化的一种---平衡多路查找树(每个节点包含更多内容，树变矮胖减少了IO次数提高了查询速度)，每个节点可以有多个子树，M阶B树表示树中最多有M个节点（M-1个关键字），所有的叶子节点都是在同一层，并且叶子节点只有关键字。
        - B+树:它是B树的优化，主要是解决了B树无法高效率地区间范围查询的问题(所有数据都在叶子节点且双向链表进行了链接)。B+树相较B树而言，所有的数据都存储在了叶子节点且叶子节点使用指针连在了一起，M阶B+树表示树中最多有M个节点(M个关键字)，且树中的非叶子节点没有直接指向数据关键字的索引只有指向子树的索引，每个非叶子节点中存储了其子节点数据集合中的最大值（非叶子节点不储存数据相对来讲能存储更多的索引键，变相降低了树的高度，减少了节点访问次数也就减少了IO所以查询速度更快）。
*  B+ 树相比 B 树的优势
    - B+ 树的磁盘读写代价更低：由于 B+ 树的中间节点不含有实际数据，只有子树的最大数据和子树指针，因此磁盘页中可以容纳更多节点元素。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多，相对来说 IO 读写次数也就降低了；
    - B+ 树的查询效率更加稳定：由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；
    - B+ 树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而 B 树只能中序遍历所有节点，效率太低。
    
* [为什么B+树比B树更适合数据库的索引？](https://blog.csdn.net/weixin_42130786/article/details/114327027)   
    - 1.B+树的磁盘IO代价更低：B+树更矮(非叶节点不存储指向真实数据的指针了节省空间能存储更多的索引键)，意味着数据库索引中更少的磁盘I/O操作，更快的速度；
    - 2.B+树的查询效率更加稳定：所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
    - 3.B+树更加适合在区间查询：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，所以B+树更加适合在区间查询的情况；
    - 结论：数据库索引采用B+树的主要原因是: B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。
### 索引的分类
* 普通索引和唯一性索引：索引列的值的唯一性
* 主键索引：指的就是主键，主键是索引的一种，是唯一索引的特殊类型（（唯一索引允许空值，主键不允许有空值）。创建主键的时候，数据库默认会为主键创建一个唯一索引；InnoDB 作为 MySQL 存储引擎时，默认按照主键进行聚集，如果没有定义主键，InnoDB 会试着使用唯一的非空索引来代替。如果没有这种索引，InnoDB 就会定义隐藏的主键然后在上面进行聚集。所以，对于聚集索引来说，你创建
主键的时候，自动就创建了主键的聚集索引。
* 单个索引和复合索引：索引列所包含的列数
* 聚集索引按照数据的物理存储进行划分的。对于一堆记录来说，使用聚集索引就是对这堆记录进行堆划分，即主要描述的是物理上的存储。聚集索引可以帮助把很大的范围，迅速减小范围，然后查找指定记录；而非聚集索引是把一个很大的范围，转换成一个小的地图，然后你需要在这个小地图中找你要寻找的信息的位置，最后通过这个位置，再去找你所需要的记录。参考自[快速理解聚集索引和非聚集索引](https://blog.csdn.net/zc474235918/article/details/50580639)
* 聚集和非聚集指：B+树叶节点存的指针还是数据记录，myISAM 非聚集（指针）innoDB聚集（指针+记录）
## MySQL 中的锁
### 乐观锁和悲观锁(都是一种思想)
https://www.cnblogs.com/laoyeye/p/8228467.html
https://blog.csdn.net/qq_32600929/article/details/89089577
* 什么是悲观锁和乐观锁？   
    - 乐观锁和悲观锁都是一种思想，并不是真实存在于数据库中的一种机制。悲观锁的实现是依赖于数据库提供的锁机制；乐观锁的实现不需要借助于数据库锁机制，主要就是两个步骤：冲突检测和数据更新，其中一种典型的是实现方法就是CAS(Compare and Swap)
    - 当认为数据被并发修改的几率比较大，需要在修改之前借助于数据库锁机制,先对数据进行加锁的思想被称为悲观锁，又称PCC(Pessimistic Concurrency Control)。在效率方面，处理锁的操作会产生了额外的开销，而且增加了死锁的机会。当一个线程在处理某行数据的时候，其它线程只能等待。
    - 乐观锁思想认为，数据一般是不会造成冲突的。只有在提交数据的时候，才会对数据的冲突进行检测。当发现冲突的时候，返回错误的信息，让用户决定如何去做。乐观锁不会使用数据库提供的锁机制，一般的实现方式就是记录数据版本。
* 悲观锁的特点是先获取锁，再进行业务操作，即 “悲观” 的认为所有的操作均会导致并发安全问题，因此要先确保获取锁成功再进行业务操作。通常来讲，在数据库上的悲观锁需要数据库本身提供支持，即通过常用的 select … for update 操作来实现悲观锁。当数据库执行 select … for update 时会获取被 select 中的数据行的行锁，因此其他并发执行的 select … for update 如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update 获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。另外还有个问题是: select… for update 语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。MySQL InnoDB默认行级锁，行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意（先上锁，再操作，一锁二查三更新）
* 乐观锁是否在事务中其实都是无所谓的，其底层机制是这样：在数据库内部 update 同一行的时候是不允许并发的，即数据库每次执行一条 update 语句时会获取被 update 行的写锁，直到这一行被成功更新后才释放。因此在业务操作进行前获取需要锁的数据的当前版本号(不使用版本号会有ABA问题，AB同时获取库存3，B操作先减再加变为原样3，这时候A操作可以成功但不正确)，然后实际更新数据时再次对比版本号确认与之前获取的相同，并更新版本号，即可确认这其间没有发生并发的修改。如果更新失败，即可认为老版本的数据已经被并发修改掉而不存在了，此时认为获取锁失败，需要回滚整个业务操作并可根据需要重试整个过程。（先修改，更新时发现数据变化就会滚）
* 悲观锁与乐观锁的应用场景：一般情况下，读多写少更适合用乐观锁（**乐观锁思想认为，数据一般是不会造成冲突的。只有在提交数据的时候，才会对数据的冲突进行检测**），读少写多更适合用悲观锁。乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能。
### MySQL 行级锁
* **MyISAM 只支持表级锁**，用户在操作MyISAM 表时，select、update、delete 和 insert语句都会给表自动加锁，如果加锁以后的表满足insert 并发的情况下，可以在表的尾部插入新的数据。**InnoDB 支持事务和行级锁，行锁大幅度提高了多用户并发操作的新能，但是 InnoDB 的行锁只是在 WHERE 的主键是有效的，非主键的 WHERE 都会锁全表。**
* 共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改。如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排它锁。SELECT ... LOCK IN SHARE MODE 会对查询出的每一条数据加共享锁，如果其它线程再加排它锁就会阻塞。
* **排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的锁，获准排他锁的事务既能读数据，又能修改数据**。SELECT ... FOR UPDATE 中会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。
## 存储引擎 MyISAM 和 InnoDB 区别
* 事务支持：**MyISAM 强调的是性能，每次查询具有原子性，其执行速度比 InnoDB 更快，但是不支持事务。InnoDB 提供事务、外键等高级数据库功能，具有事务提交、回滚能力**。
* AUTO_INCREMENT：对AUTO_INCREMENT的处理方式不一样。如果将某个字段设置为INCREMENT，InnoDB中规定必须包含只有该字段的索引，如果是组合索引也必须是组合索引的第一列。但是在MyISAM中，可以将该字段和其他字段一起建立组合索引，可以不是第一列。
* 表主键：MyISAM 允许没有任何索引和主键的表存在，索引都是保存行的地址。对于 InnoDB，如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键 (用户不可见)，数据是主索引的一部分。
* 表的具体行数：MyISAM内置了一个计数器来存储表的行数。执行 select count(*)时直接从计数器中读取，速度非常快。而 InnoDB不保存这些信息，如果使用 select count( *) from table 就会遍历整个表，消耗相当大。（在加了wehre 条件后，myisam 和 innodb 处理的方式都一样）
* 全文索引：MyISAM支持 FULLTEXT类型的全文索引，InnoDB不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。
* 外键：MyISAM 不支持外键，而 InnoDB 支持外键。
* 存储结构：每个 MyISAM 在磁盘上存储成三个文件：第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm 文件存储表定义，数据文件的扩展名为. MYD (MYData)，索引文件的扩展名是. MYI(MYIndex)。InnoDB 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB 表的大小只受限于操作系统文件的大小，一般为 2GB。
* CURD操作：如果执行大量的SELECT，MyISAM是更好的选择。如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。
## [实现MVCC](https://www.cnblogs.com/xuwc/p/13873611.html)
* MVCC 全称是Multi-Version Concurrent Control，即多版本并发控制，在MVCC协议下，每个读操作会看到一个一致性的snapshot，并且可以实现非阻塞的读。MVCC允许数据具有多个版本，这个版本可以是时间戳或者是全局递增的事务ID，在同一个时间点，不同的事务看到的数据是不同的。
* innodb会为每一行添加两个字段，分别表示该行创建的版本和删除的版本，填入的是事务的版本号，这个版本号随着事务的创建不断递增。在repeated read的隔离级别下，具体各种数据库操作的实现：
    * select：满足以下两个条件innodb会返回该行数据：该行的创建版本号小于等于当前版本号，用于保证在select操作之前所有的操作已经执行落地。该行的删除版本号大于当前版本或者为空。删除版本号大于当前版本意味着有一个并发事务将该行删除了。
    * insert：将新插入的行的创建版本号设置为当前系统的版本号。
    * delete：将要删除的行的删除版本号设置为当前系统的版本号。
    * update：不执行原地update，而是转换成insert + delete。将旧行的删除版本号设置为当前版本号，并将新行insert同时设置创建版本号为当前版本号。
* 其中，写操作（insert、delete和update）执行时，需要将系统版本号递增。由于旧数据并不真正的删除，所以必须对这些数据进行清理，innodb会开启一个后台线程执行清理工作，具体的规则是将删除版本号小于当前系统版本的行删除，这个过程叫做purge。通过MVCC很好的实现了事务的隔离性，可以达到repeated read级别，要实现serializable还必须加锁。
## 实践中如何优化 MySQL
* 实践中，MySQL 的优化主要涉及 SQL 语句的优化，索引的优化，数据表结构的优化。其他包括系统配置和硬件的优化。
### SQL 语句的优化
* 发现有问题的 SQL：MySQL 的慢查询日志是 MySQL 提供的一种日志记录，用来记录在 MySQL 中响应时间超过阀值的语句，具体指运行时间超过 long_query_time(long_query_time 的默认值为 10，意思是运行10s 以上的语句。) 值的 SQL，则会被记录到慢查询日志中。通过 MySQL 的慢查询日志可以查询出执行次数多、占用时间长的 SQL，用 pt_query_disgest(一种 mysql 慢日志分析工具) 分析 Rows examine(MySQL 执行器需要检查的行数) 项去找出 IO 大的 SQL 以及发现未命中索引的 SQL，对其进行优化。
* 分析 SQL 的执行计划：使用 EXPLAIN 关键字可以知道 MySQL 是如何处理 SQL 语句的，以便分析查询语句或是表结构的性能瓶颈。通过 explain 命令可以得到表的读取顺序、哪些索引被实际使用、表之间的引用以及每张表有多少行被优化器查询等问题。当扩展列 extra 出现 Using filesort 和 Using temporay，则往往表示SQL 需要优化了。具体参考[MySQL 性能优化神器 Explain 使用分析](https://segmentfault.com/a/1190000008131735)
* 优化 SQL 语句：
    - 优化 insert 语句：一次插入多值
    - 应尽量避免在 where 子句中使用!= 或 <> 操作符，则将引擎放弃使用索引而进行全表扫描；
    - 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描；
    - 优化嵌套查询：子查询可以被更有效率的连接 (Join)替代；
    - 很多时候用 exists 代替 in 是一个好的选择。
### 索引的优化
* 适合创建索引的字段
    - 经常作查询选择的字段
    - 经常作表连接的字段
    - 经常出现在 order by, group by, distinct 后面的字段
* 创建索引时需要注意什么
    - 非空字段：应该指定列为 NOT NULL，除非你想存储NULL。在 MySQL 中含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用 0、一个特殊的值或者一个空串代替空值；
    - 取值离散大的字段（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过 count() 函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
    - 索引字段越小越好：数据库的数据存储以页为单位，一页存储的数据越多，一次 IO 操作获取的数据越多，效率越高。
* 索引失效的情况
    - 以 “%(表示任意 0 个或多个字符)” 开头的 LIKE 语句，模糊匹配；
    - OR 语句前后没有同时使用索引；
    - 数据类型出现隐式转化（如 varchar 不加单引号的话可能会自动转换为 int 型）；
    - 对于多列索引，必须满足 最左匹配原则 (eg：多列索引 col1、col2 和 col3，则 索引生效的情形包括 col1或 col1，col2 或 col1，col2，col3)。
### 数据表结构的优化
* 选择合适数据类型
    - 使用较小的数据类型解决问题；
    - 使用简单的数据类型 (mysql 处理 int 要比 varchar容易)；
    - 尽可能的使用 not null 定义字段；
    - 尽量避免使用 text 类型，非用不可时最好考虑分表。
* 表的范式的优化，一般情况下表的设计应该遵循三大范式。
* 表的垂直拆分
    - 把不常用的字段单独放在同一个表中；
    - 把大字段独立放入一个表中；
    - 把经常使用的字段放在一起；
* 表的水平拆分
    - 表的水平拆分用于解决数据表中数据过大的问题，水平拆分每一个表的结构都是完全一致的。一般地，将数据平分到 N 张表中的常用方法。包括以下两种：对 ID 进行 hash 运算，如果要拆分成 5 个表，mod(id,5) 取出 0~4 个值；针对不同的 hashID 将数据存入不同的表中；
    - 表分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询速度；
    - 表中的数据本来就有独立性，例如表中分别记录各个地区的数据或不同时期的数据，特别是有些数据常用，而另外一些数据不常用。
## Redis
* 参考 [面试中关于Redis的问题看这篇就够了](https://blog.csdn.net/qq_34337272/article/details/80012284)
* Redis 是一个使用 C 语言写成的，开源的 key-value 数据库。和Memcached类似，但支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型），这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序，与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。
* 适合存储在非关系型数据库中的数据：关系不是很密切的的数据，比如用户信息，班级信息，评论数量等等；量比较大的数据，如访问记录等；访问比较频繁的数据，如用户信息，访问数量，最新微博等。
### Redis数据类型
* string 常用命令: set,get,decr,incr,mget ，是最基本的数据类型，一个键对应一个值，需要注意是一个键值最大存储512MB。用于常规计数：微博数，粉丝数等。
* hash 常用命令：hget,hset,hgetall 等，redis hash是一个键值对的集合，是一个string类型的field和value的映射表，适用于存储用户信息，商品信息。
* List 常用命令: lpush,rpush,lpop,rpop,lrange等，是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，最新消息排行等功能都可以用Redis的list结构来实现。Redis list的实现为一个双向链表，可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
* Set常用命令：sadd,spop,smembers,sunion 等，对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动去重的，并且set提供了判断某个成员是否在一个set集合内的重要接口。在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同喜好、二度好友等功能。
* Sorted Set常用命令： zadd,zrange,zrem,zcard 等，和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按  score 进行有序排列。（直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用Redis中的SortedSet结构进行存储。）
### Redis的应用场景
* 访问热点数据，减少响应时间，提升吞吐量
    * 会话缓存（最常用）
    * 消息队列，比如支付
    * 活动排行榜或计数
    * 发布，订阅消息（消息通知）
    * 商品列表，评论列表等
### Redis 持久化
* 参考[redis的持久化和缓存机制](https://blog.csdn.net/tr1912/article/details/70197085?foxhandler=RssReadRenderProcessHandler)
* 快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。可以配置 redis在 n 秒内如果超过 m 个 key 被修改就自动做快照，下面是默认的快照保存配置：
```
保存 900 1   # 900秒内如果超过1个Key被修改，则启动快照保存
保存300 10   # 300秒内如果超过10个Key被修改，则启动快照保存
保存60 10000 # 60秒内如果超过10000个Key被修改，则启动快照保存 
```
* aof 比快照方式有更好的持久化性，是由于在使用 aof 持久化方式时,redis 会将每一个收到的写命令都通过 write 函数追加到文件中(默认是 appendonly.aof)。当 redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容，AOF持久化存储方式参数说明
```
appendonly yes  # 开启AOF持久化存储方式 
appendfsync always  # 收到写命令后就立即写入磁盘，效率最差，效果最好
appendfsync everysec  # 每秒写入磁盘一次，效率与效果居中
appendfsync no  # 完全依赖操作系统，效率最佳，效果没法保证
```
### 缓存使用过程中的坑
* 引用自 [缓存穿透，缓存击穿，缓存雪崩解决方案分析](https://blog.csdn.net/zeb_perfect/article/details/54135506)
* 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。解决方案：如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
* 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。解决方案：将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
* 缓存击穿，对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
### 其他问题
* 高并发场景下数据重复插入的问题
    * 使用关系型数据库的唯一索引
    * Redis 实现分布式锁：
* Redis常见性能问题和解决方案
    * Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
    * 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
    * 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
    * 尽量避免在压力很大的主库上增加从库